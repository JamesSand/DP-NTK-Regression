{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nvme2/xuhaiyang/softwares/anaconda3/envs/galore/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mnt/nvme2/xuhaiyang/softwares/anaconda3/envs/galore/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from torch.distributions.laplace import Laplace\n",
    "import math\n",
    "from ntk_utils import gen_h_dis, gen_alpha, gen_z_embed, process_query\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# the following code is adapted from\n",
    "# https://github.com/josharnoldjosh/Resnet-Extract-Image-Feature-Pytorch-Python \n",
    "\n",
    "# Load the pretrained resnet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Use the model object to select the desired layer\n",
    "layer = model._modules.get('avgpool')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Image transforms\n",
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def get_vector(img):\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512).to(device)\n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "        # my_embedding.copy_(o.data)\n",
    "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    # 6. Run the model on our transformed image\n",
    "    t_img = t_img.to(device)\n",
    "    model(t_img)\n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()\n",
    "\n",
    "    return my_embedding\n",
    "\n",
    "# download cifar10 dataset\n",
    "ds = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "def gen_2classes_indices(cls1_name, cls2_name):\n",
    "    cls1_indices, cls2_indices, other_indices = [], [], []\n",
    "    cls1_idx, cls2_idx = ds.class_to_idx[cls1_name], ds.class_to_idx[cls2_name]\n",
    "\n",
    "    for i in range(len(ds)):\n",
    "        current_class = ds[i][1]\n",
    "        if current_class == cls1_idx:\n",
    "            cls1_indices.append(i)\n",
    "        elif current_class == cls2_idx:\n",
    "            cls2_indices.append(i)\n",
    "        else:\n",
    "            other_indices.append(i)\n",
    "\n",
    "    return cls1_indices, cls2_indices\n",
    "\n",
    "def gen_feature_tensor(idx_list):\n",
    "    img_ts_list = []\n",
    "    for idx in tqdm(idx_list):\n",
    "        image, label = ds[idx]\n",
    "        img_ts = get_vector(image)\n",
    "        img_ts_list.append(img_ts)\n",
    "\n",
    "    # concat\n",
    "    ret_ts = torch.stack(img_ts_list, dim=0)\n",
    "    return ret_ts\n",
    "\n",
    "\n",
    "def test_accuracy(test_dataset, gt_label, w_r, x_data, alpha):\n",
    "    pred = process_query(test_dataset, w_r, x_data, alpha)\n",
    "    succ_cnt = torch.sum(pred == gt_label)\n",
    "    nz = pred.shape[0]\n",
    "    accuracy = succ_cnt / nz\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def cal_k(eps, delta, beta):\n",
    "    eta = 7e-3\n",
    "    n = 1e3\n",
    "    k_bound = (eps * eps * eta * eta) / (8 * math.log(1 / delta) * n * n * beta * beta)\n",
    "    k = int(math.floor(k_bound))\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 175.49it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 197.29it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 203.83it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 203.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data normalized\n",
      "data normalized\n",
      "data normalized\n",
      "data normalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc tensor(0.9800, device='cuda:0')\n",
      "train acc tensor(0.9810, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######### normalization x data start ###########\n",
    "def calculate_norm(input_data):\n",
    "    # input_data: n * d\n",
    "    square_data = input_data * input_data\n",
    "    norm_data = square_data.sum(dim=1)\n",
    "    norm_data = torch.sqrt(norm_data)\n",
    "    return norm_data\n",
    "\n",
    "def data_normalization(input_data):\n",
    "    # input data: n * d\n",
    "    # print(\"data normalized\")\n",
    "    x_norm = calculate_norm(input_data)\n",
    "    x_norm = x_norm[..., None]\n",
    "    ball_data = input_data / x_norm\n",
    "\n",
    "    return ball_data\n",
    "######### normalization x data end ###########\n",
    "\n",
    "# there are 5k images for 1 class\n",
    "train_num = 1000\n",
    "test_num = 100\n",
    "label_scale = 1.0\n",
    "\n",
    "# random choose two classes from all 10 classes\n",
    "cls1_name = \"airplane\"\n",
    "cls2_name = \"cat\"\n",
    "\n",
    "cls1_indices, cls2_indices = gen_2classes_indices(cls1_name, cls2_name)\n",
    "\n",
    "cls1_train_ts = gen_feature_tensor(cls1_indices[:train_num]).to(device)\n",
    "cls2_train_ts = gen_feature_tensor(cls2_indices[:train_num]).to(device)\n",
    "\n",
    "cls1_label = torch.full((train_num, ), label_scale, dtype=torch.float32)\n",
    "cls2_label = torch.full((train_num, ), -1 * label_scale, dtype=torch.float32)\n",
    "\n",
    "cls1_test_ts = gen_feature_tensor(cls1_indices[-test_num:]).to(device)\n",
    "cls2_test_ts = gen_feature_tensor(cls2_indices[-test_num:]).to(device)\n",
    "\n",
    "############# test on NTK Regression start #################\n",
    "\n",
    "######### normalization start ################\n",
    "cls1_train_ts = data_normalization(cls1_train_ts)\n",
    "cls2_train_ts = data_normalization(cls2_train_ts)\n",
    "cls1_test_ts = data_normalization(cls1_test_ts)\n",
    "cls2_test_ts = data_normalization(cls2_test_ts)\n",
    "######### normalization end ################\n",
    "\n",
    "\n",
    "m = 256\n",
    "reg_lambda = 10.0\n",
    "\n",
    "x_data = torch.cat((cls1_train_ts, cls2_train_ts), dim=0).to(device)\n",
    "y_data = torch.cat((cls1_label, cls2_label), dim=0).to(device)\n",
    "\n",
    "n, d = x_data.shape\n",
    "\n",
    "# generate w_r\n",
    "w_r = torch.randn((m, d), dtype=torch.float32).to(device)\n",
    "\n",
    "h_dis = gen_h_dis(w_r, x_data)\n",
    "\n",
    "# calculate NTK Regression alpha\n",
    "alpha = gen_alpha(h_dis, reg_lambda, y_data)\n",
    "\n",
    "def gaussain_sampling_on_k(h_dis, y_data, reg_lambda, cls1_test_ts, cls2_test_ts, k=None):\n",
    "    \n",
    "    n = h_dis.shape[0]\n",
    "\n",
    "    test_acc_list = []\n",
    "    train_acc_list = []\n",
    "\n",
    "    # more repeat time for lower variance in results\n",
    "    repeat_time = 10\n",
    "    for _ in tqdm(range(repeat_time)):\n",
    "        if k is None:\n",
    "            wt_h_dis = h_dis\n",
    "        else:\n",
    "            # setup gaussian sampler\n",
    "            gaussian_sampler = torch.distributions.MultivariateNormal(\n",
    "                loc=torch.zeros(n).to(device), covariance_matrix=h_dis\n",
    "            )\n",
    "\n",
    "            # gausian sampling\n",
    "            wt_h_dis = torch.empty(k, n, n).to(device)\n",
    "\n",
    "            for i in range(k):\n",
    "                sample_vec = gaussian_sampler.sample()\n",
    "                wt_h_dis[i] = sample_vec[..., None] @ sample_vec[None, ...]\n",
    "\n",
    "            # take mean over dim k\n",
    "            # n * n\n",
    "            wt_h_dis = wt_h_dis.mean(dim=0)\n",
    "\n",
    "        alpha = gen_alpha(wt_h_dis, reg_lambda, y_data)\n",
    "\n",
    "        alpha = alpha / (n * n)\n",
    "\n",
    "        cls1_accuracy = test_accuracy(cls1_test_ts, 1, w_r, x_data, alpha)\n",
    "        cls2_accuracy = test_accuracy(cls2_test_ts, -1, w_r, x_data, alpha)\n",
    "\n",
    "        cls1_train_acc = test_accuracy(cls1_train_ts, 1, w_r, x_data, alpha)\n",
    "        cls2_train_acc = test_accuracy(cls2_train_ts, -1, w_r, x_data, alpha)\n",
    "\n",
    "        cur_test_acc = (cls1_accuracy + cls2_accuracy) / 2\n",
    "        cur_train_acc = (cls1_train_acc + cls2_train_acc) / 2\n",
    "\n",
    "        test_acc_list.append((cls1_accuracy + cls2_accuracy) / 2)\n",
    "        train_acc_list.append((cls1_train_acc + cls2_train_acc) / 2)\n",
    "\n",
    "    final_test_acc = sum(test_acc_list) / len(test_acc_list)\n",
    "    final_train_acc = sum(train_acc_list) / len(train_acc_list)\n",
    "\n",
    "    return final_test_acc, final_train_acc\n",
    "\n",
    "############ test trained kernel start ###############\n",
    "final_test_acc, final_train_acc = gaussain_sampling_on_k(h_dis, y_data, reg_lambda, cls1_test_ts, cls2_test_ts, None)\n",
    "\n",
    "print(\"test acc\", final_test_acc)\n",
    "print(\"train acc\", final_train_acc)\n",
    "############ test trained kernel end ###############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "eps exponent -0.4, k 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc tensor(0.8025, device='cuda:0')\n",
      "train acc tensor(0.8103, device='cuda:0')\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "eps exponent -0.3, k 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc tensor(0.8630, device='cuda:0')\n",
      "train acc tensor(0.8726, device='cuda:0')\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fix beta and delta\n",
    "beta = 1e-6\n",
    "delta = 1e-3\n",
    "\n",
    "# we run different eps exponent, from (0.5, 1.5)\n",
    "eps_exponent_list = [0.5 + i * 0.1 for i in range(11)]\n",
    "\n",
    "\n",
    "# we store all private test acc and private train acc. For later draw figure.\n",
    "draw_test_acc_list = []\n",
    "draw_train_acc_list = []\n",
    "\n",
    "\n",
    "for eps_exponent in eps_exponent_list:\n",
    "    eps = 10 ** eps_exponent\n",
    "    # calculate number of Gaussian Samples according to eps\n",
    "    k = cal_k(eps, delta, beta)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    print(f\"eps exponent {eps_exponent}, k {k}\")\n",
    "\n",
    "    # get private test acc and train acc\n",
    "    final_test_acc, final_train_acc = gaussain_sampling_on_k(h_dis, y_data, reg_lambda, cls1_test_ts, cls2_test_ts, k)\n",
    "    \n",
    "    print(\"test acc\", final_test_acc)\n",
    "    print(\"train acc\", final_train_acc)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    draw_test_acc_list.append(final_test_acc)\n",
    "    draw_train_acc_list.append(final_train_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.tensor() to python float\n",
    "draw_test_acc_list = [x.item() for x in draw_test_acc_list]\n",
    "draw_train_acc_list = [x.item() for x in draw_train_acc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5, -0.4, -0.3, -0.19999999999999996, -0.09999999999999998, 0.0, 0.10000000000000009, 0.20000000000000007, 0.30000000000000004, 0.4, 0.5]\n",
      "[0.7705000638961792, 0.8830000162124634, 0.8434999585151672, 0.9180000424385071, 0.9084998965263367, 0.9545000195503235, 0.9790000319480896, 0.9689998626708984, 0.9794999957084656, 0.9805000424385071, 0.981499969959259]\n",
      "[0.7839500308036804, 0.8832500576972961, 0.8475000262260437, 0.9182001352310181, 0.9191500544548035, 0.9565500617027283, 0.9762499928474426, 0.9739500284194946, 0.9793000221252441, 0.9796000719070435, 0.9799000024795532]\n"
     ]
    }
   ],
   "source": [
    "# you need to copy the output to gaussian_draw.ipynb to draw the figures.\n",
    "print(eps_exponent_list)\n",
    "print(draw_test_acc_list)\n",
    "print(draw_train_acc_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
