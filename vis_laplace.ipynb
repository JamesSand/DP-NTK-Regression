{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nvme2/xuhaiyang/softwares/anaconda3/envs/galore/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mnt/nvme2/xuhaiyang/softwares/anaconda3/envs/galore/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from torch.distributions.laplace import Laplace\n",
    "\n",
    "\n",
    "from ntk_utils import gen_h_dis, gen_alpha, gen_z_embed, process_query\n",
    "\n",
    "# device =\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Use the model object to select the desired layer\n",
    "layer = model._modules.get('avgpool')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Image transforms\n",
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def get_vector(img):\n",
    "    # 1. Load the image with Pillow library\n",
    "    # img = Image.open(image_name)\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512).to(device)\n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "        # my_embedding.copy_(o.data)\n",
    "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    # 6. Run the model on our transformed image\n",
    "    # origin_device = t_img.device\n",
    "    t_img = t_img.to(device)\n",
    "    model(t_img)\n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()\n",
    "\n",
    "    return my_embedding\n",
    "\n",
    "    # my_embedding = my_embedding.to(origin_device)\n",
    "    # # 8. Return the feature vector\n",
    "    # return my_embedding.numpy()\n",
    "\n",
    "\n",
    "ds = torchvision.datasets.CIFAR10(root='./data', train=True, download=False)\n",
    "\n",
    "def gen_2classes_indices(cls1_name, cls2_name):\n",
    "    cls1_indices, cls2_indices, other_indices = [], [], []\n",
    "    cls1_idx, cls2_idx = ds.class_to_idx[cls1_name], ds.class_to_idx[cls2_name]\n",
    "\n",
    "    for i in range(len(ds)):\n",
    "        current_class = ds[i][1]\n",
    "        if current_class == cls1_idx:\n",
    "            cls1_indices.append(i)\n",
    "        elif current_class == cls2_idx:\n",
    "            cls2_indices.append(i)\n",
    "        else:\n",
    "            other_indices.append(i)\n",
    "\n",
    "    return cls1_indices, cls2_indices\n",
    "\n",
    "def gen_feature_tensor(idx_list):\n",
    "    img_ts_list = []\n",
    "    for idx in tqdm(idx_list):\n",
    "        image, label = ds[idx]\n",
    "        img_ts = get_vector(image)\n",
    "        # img_ts = torch.from_numpy(img_np)\n",
    "        img_ts_list.append(img_ts)\n",
    "\n",
    "    # concat\n",
    "    ret_ts = torch.stack(img_ts_list, dim=0)\n",
    "    return ret_ts\n",
    "\n",
    "\n",
    "def test_accuracy(test_dataset, gt_label, w_r, x_data, alpha):\n",
    "    pred = process_query(test_dataset, w_r, x_data, alpha)\n",
    "    succ_cnt = torch.sum(pred == gt_label)\n",
    "    nz = pred.shape[0]\n",
    "    accuracy = succ_cnt / nz\n",
    "    # print(\"accuracy\", accuracy)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 201.84it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 204.60it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 205.49it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 206.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# there are 5k images for 1 class\n",
    "train_num = 1000\n",
    "test_num = 100\n",
    "# label_scale = 1e12\n",
    "label_scale = 1.0\n",
    "\n",
    "cls1_name = \"airplane\"\n",
    "cls2_name = \"cat\"\n",
    "\n",
    "cls1_indices, cls2_indices = gen_2classes_indices(cls1_name, cls2_name)\n",
    "\n",
    "cls1_train_ts = gen_feature_tensor(cls1_indices[:train_num]).to(device)\n",
    "cls2_train_ts = gen_feature_tensor(cls2_indices[:train_num]).to(device)\n",
    "\n",
    "cls1_label = torch.full((train_num, ), label_scale, dtype=torch.float32)\n",
    "cls2_label = torch.full((train_num, ), -1 * label_scale, dtype=torch.float32)\n",
    "\n",
    "cls1_test_ts = gen_feature_tensor(cls1_indices[-test_num:]).to(device)\n",
    "cls2_test_ts = gen_feature_tensor(cls2_indices[-test_num:]).to(device)\n",
    "\n",
    "\n",
    "############# test on NTK Regression start #################\n",
    "\n",
    "m = 256\n",
    "reg_lambda = 10.0\n",
    "\n",
    "x_data = torch.cat((cls1_train_ts, cls2_train_ts), dim=0).to(device)\n",
    "y_data = torch.cat((cls1_label, cls2_label), dim=0).to(device)\n",
    "\n",
    "n, d = x_data.shape\n",
    "\n",
    "# generate w_r\n",
    "w_r = torch.randn((m, d), dtype=torch.float32).to(device)\n",
    "\n",
    "h_dis = gen_h_dis(w_r, x_data)\n",
    "\n",
    "alpha = gen_alpha(h_dis, reg_lambda, y_data)\n",
    "\n",
    "# # may scale down alpha here\n",
    "# alpha = alpha / (n * n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "test acc tensor(0.9720, device='cuda:0')\n",
      "train acc tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "test acc tensor(0.9785, device='cuda:0')\n",
      "train acc tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "test acc tensor(0.9150, device='cuda:0')\n",
      "train acc tensor(0.9596, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "test acc tensor(0.5065, device='cuda:0')\n",
      "train acc tensor(0.5088, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "test acc tensor(0.5630, device='cuda:0')\n",
      "train acc tensor(0.5663, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "test acc tensor(0.4600, device='cuda:0')\n",
      "train acc tensor(0.4602, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "test acc tensor(0.4900, device='cuda:0')\n",
      "train acc tensor(0.4875, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:11,  1.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exponent \u001b[38;5;129;01min\u001b[39;00m exponent_eps_list:\n\u001b[1;32m     61\u001b[0m     eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (exponent)\n\u001b[0;32m---> 63\u001b[0m     final_test_acc, final_train_acc \u001b[38;5;241m=\u001b[39m \u001b[43madd_laplace_on_alpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls1_test_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls2_test_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(exponent)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, final_test_acc)\n",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m, in \u001b[0;36madd_laplace_on_alpha\u001b[0;34m(cls1_test_ts, cls2_test_ts, alpha, reg_lambda, w_r, x_data, eps)\u001b[0m\n\u001b[1;32m     21\u001b[0m cls1_accuracy \u001b[38;5;241m=\u001b[39m test_accuracy(cls1_test_ts, \u001b[38;5;241m1\u001b[39m, w_r, x_data, wt_alpha)\n\u001b[1;32m     22\u001b[0m cls2_accuracy \u001b[38;5;241m=\u001b[39m test_accuracy(cls2_test_ts, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, w_r, x_data, wt_alpha)\n\u001b[0;32m---> 24\u001b[0m cls1_train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls1_train_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwt_alpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m cls2_train_acc \u001b[38;5;241m=\u001b[39m test_accuracy(cls2_train_ts, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, w_r, x_data, wt_alpha)\n\u001b[1;32m     27\u001b[0m test_acc_list\u001b[38;5;241m.\u001b[39mappend((cls1_accuracy \u001b[38;5;241m+\u001b[39m cls2_accuracy) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 93\u001b[0m, in \u001b[0;36mtest_accuracy\u001b[0;34m(test_dataset, gt_label, w_r, x_data, alpha)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_accuracy\u001b[39m(test_dataset, gt_label, w_r, x_data, alpha):\n\u001b[0;32m---> 93\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     succ_cnt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(pred \u001b[38;5;241m==\u001b[39m gt_label)\n\u001b[1;32m     95\u001b[0m     nz \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/szz/ntk_kernel/ntk_utils.py:115\u001b[0m, in \u001b[0;36mprocess_query\u001b[0;34m(z, w_r, x_data, alpha)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_query\u001b[39m(z, w_r, x_data, alpha):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# z: nz * d\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# w_r: m * d\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# nz * n\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     query_embed \u001b[38;5;241m=\u001b[39m \u001b[43mgen_z_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# nz * 1\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     query_pred \u001b[38;5;241m=\u001b[39m query_embed \u001b[38;5;241m@\u001b[39m alpha\n",
      "File \u001b[0;32m~/szz/ntk_kernel/ntk_utils.py:88\u001b[0m, in \u001b[0;36mgen_z_embed\u001b[0;34m(z, x_data, w_r)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# 1 * n\u001b[39;00m\n\u001b[1;32m     86\u001b[0m inner_z_xi \u001b[38;5;241m=\u001b[39m z \u001b[38;5;241m@\u001b[39m x_data\u001b[38;5;241m.\u001b[39mt()\n\u001b[0;32m---> 88\u001b[0m inner_wr_z_wr_xi \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# breakpoint()\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def add_laplace_on_alpha(cls1_test_ts, cls2_test_ts, alpha, reg_lambda, w_r, x_data,  eps=None):\n",
    "    # for loop here\n",
    "    test_acc_list = []\n",
    "    train_acc_list = []\n",
    "\n",
    "    for i in tqdm(range(10)):\n",
    "      \n",
    "        if eps is None:\n",
    "            wt_alpha = alpha\n",
    "        else:\n",
    "            n = alpha.shape[0]\n",
    "            # Delta = 3 / (n * reg_lambda)\n",
    "            Delta = 2 * n / reg_lambda\n",
    "            dp_lambda = Delta / eps\n",
    "\n",
    "            laplace_sampler = Laplace(torch.tensor([0.0]), torch.tensor([dp_lambda]))\n",
    "            laplace_noise = laplace_sampler.sample((n, )).to(alpha.device)\n",
    "            laplace_noise = laplace_noise[..., 0]\n",
    "            wt_alpha = alpha + laplace_noise\n",
    "\n",
    "        cls1_accuracy = test_accuracy(cls1_test_ts, 1, w_r, x_data, wt_alpha)\n",
    "        cls2_accuracy = test_accuracy(cls2_test_ts, -1, w_r, x_data, wt_alpha)\n",
    "\n",
    "        cls1_train_acc = test_accuracy(cls1_train_ts, 1, w_r, x_data, wt_alpha)\n",
    "        cls2_train_acc = test_accuracy(cls2_train_ts, -1, w_r, x_data, wt_alpha)\n",
    "\n",
    "        test_acc_list.append((cls1_accuracy + cls2_accuracy) / 2)\n",
    "        train_acc_list.append((cls1_train_acc + cls2_train_acc) / 2)\n",
    "\n",
    "    final_test_acc = sum(test_acc_list) / len(test_acc_list)\n",
    "    final_train_acc = sum(train_acc_list) / len(train_acc_list)\n",
    "\n",
    "    return final_test_acc, final_train_acc\n",
    "\n",
    "# # 1e-3 not ok\n",
    "# # 8e-3 little ok\n",
    "# eps = 1e-2\n",
    "# # eps = None\n",
    "\n",
    "# test_eps = 1e12\n",
    "\n",
    "# final_test_acc, final_train_acc = add_laplace_on_alpha(cls1_test_ts, cls2_test_ts, alpha, reg_lambda, w_r, x_data, 1e12)\n",
    "\n",
    "# # print(exponent)\n",
    "# print(\"test acc\", final_test_acc)\n",
    "# print(\"train acc\", final_train_acc)\n",
    "\n",
    "# raise\n",
    "\n",
    "exponent_eps_list = list(range(12, 0, -1))\n",
    "print(exponent_eps_list)\n",
    "\n",
    "# raise\n",
    "\n",
    "# exponent_eps_list = [-3.0 + i * 0.2 for i in range(11)]\n",
    "# exponent_eps_list = [-1.0]\n",
    "draw_test_acc_list = []\n",
    "draw_train_acc_list = []\n",
    "\n",
    "for exponent in exponent_eps_list:\n",
    "    eps = 10 ** (exponent)\n",
    "\n",
    "    final_test_acc, final_train_acc = add_laplace_on_alpha(cls1_test_ts, cls2_test_ts, alpha, reg_lambda, w_r, x_data, eps)\n",
    "\n",
    "    print(exponent)\n",
    "    print(\"test acc\", final_test_acc)\n",
    "    print(\"train acc\", final_train_acc)\n",
    "\n",
    "    draw_test_acc_list.append(final_test_acc)\n",
    "    draw_train_acc_list.append(final_train_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.2970e-05, device='cuda:0')\n",
      "tensor(9.7769e-09, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(max(torch.abs(alpha)))\n",
    "print(min(torch.abs(alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_test_acc_list = [x.item() for x in draw_test_acc_list]\n",
    "draw_train_acc_list = [x.item() for x in draw_train_acc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.0, -2.8, -2.6, -2.4, -2.2, -2.0, -1.7999999999999998, -1.5999999999999999, -1.4, -1.2]\n",
      "[0.5375000238418579, 0.5550000071525574, 0.6184999942779541, 0.6510000228881836, 0.7055000066757202, 0.7290000319480896, 0.7945000529289246, 0.9430000185966492, 0.9545000195503235, 0.9719999432563782]\n",
      "[0.5410500168800354, 0.5646499991416931, 0.6327500343322754, 0.6720000505447388, 0.7502500414848328, 0.7677499651908875, 0.8368999361991882, 0.9946500658988953, 0.9922000169754028, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# exponent_eps_list = [-3.0 + i * 0.2 for i in range(10)]\n",
    "# draw_test_acc_list = []\n",
    "# draw_train_acc_list = []\n",
    "\n",
    "print(exponent_eps_list)\n",
    "print(draw_test_acc_list)\n",
    "print(draw_train_acc_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
