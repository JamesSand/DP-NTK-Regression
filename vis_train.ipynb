{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nvme2/xuhaiyang/softwares/anaconda3/envs/galore/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mnt/nvme2/xuhaiyang/softwares/anaconda3/envs/galore/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 151.42it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 203.85it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 203.70it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 206.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from main import gen_h_dis, gen_alpha, gen_z_embed, process_query\n",
    "\n",
    "# device =\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Load the pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Use the model object to select the desired layer\n",
    "layer = model._modules.get('avgpool')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Image transforms\n",
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def get_vector(img):\n",
    "    # 1. Load the image with Pillow library\n",
    "    # img = Image.open(image_name)\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512)\n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "        # my_embedding.copy_(o.data)\n",
    "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    # 6. Run the model on our transformed image\n",
    "    origin_device = t_img.device\n",
    "    t_img = t_img.to(device)\n",
    "    model(t_img)\n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()\n",
    "\n",
    "    my_embedding = my_embedding.to(origin_device)\n",
    "    # 8. Return the feature vector\n",
    "    return my_embedding.numpy()\n",
    "\n",
    "\n",
    "ds = torchvision.datasets.CIFAR10(root='./data', train=True, download=False)\n",
    "\n",
    "cls1_name = \"airplane\"\n",
    "cls2_name = \"cat\"\n",
    "\n",
    "cls1_indices, cls2_indices, other_indices = [], [], []\n",
    "cls1_idx, cls2_idx = ds.class_to_idx[cls1_name], ds.class_to_idx[cls2_name]\n",
    "\n",
    "for i in range(len(ds)):\n",
    "  current_class = ds[i][1]\n",
    "  if current_class == cls1_idx:\n",
    "    cls1_indices.append(i)\n",
    "  elif current_class == cls2_idx:\n",
    "    cls2_indices.append(i)\n",
    "  else:\n",
    "    other_indices.append(i)\n",
    "\n",
    "def gen_feature_tensor(idx_list):\n",
    "    img_ts_list = []\n",
    "    for idx in tqdm(idx_list):\n",
    "        image, label = ds[idx]\n",
    "        img_np = get_vector(image)\n",
    "        img_ts = torch.from_numpy(img_np)\n",
    "        img_ts_list.append(img_ts)\n",
    "\n",
    "    # concat\n",
    "    ret_ts = torch.stack(img_ts_list, dim=0)\n",
    "    return ret_ts\n",
    "\n",
    "\n",
    "# there are 5k images for 1 class\n",
    "train_num = 1000\n",
    "test_num = 100\n",
    "label_scale = 100.0\n",
    "\n",
    "cls1_train_ts = gen_feature_tensor(cls1_indices[:train_num]).to(device)\n",
    "cls2_train_ts = gen_feature_tensor(cls2_indices[:train_num]).to(device)\n",
    "\n",
    "cls1_label = torch.full((train_num, ), label_scale, dtype=torch.float32)\n",
    "cls2_label = torch.full((train_num, ), -1 * label_scale, dtype=torch.float32)\n",
    "\n",
    "cls1_test_ts = gen_feature_tensor(cls1_indices[-test_num:]).to(device)\n",
    "cls2_test_ts = gen_feature_tensor(cls2_indices[-test_num:]).to(device)\n",
    "\n",
    "############# test on NTK Regression start #################\n",
    "\n",
    "m = 256\n",
    "reg_lambda = 10.0\n",
    "\n",
    "x_data = torch.cat((cls1_train_ts, cls2_train_ts), dim=0).to(device)\n",
    "y_data = torch.cat((cls1_label, cls2_label), dim=0).to(device)\n",
    "\n",
    "n, d = x_data.shape\n",
    "\n",
    "# generate w_r\n",
    "w_r = torch.randn((m, d), dtype=torch.float32).to(device)\n",
    "\n",
    "h_dis = gen_h_dis(w_r, x_data)\n",
    "\n",
    "alpha = gen_alpha(h_dis, reg_lambda, y_data)\n",
    "\n",
    "############### sanity check part 1 start ################\n",
    "sanity_pred = process_query(cls1_train_ts, w_r, x_data, alpha)\n",
    "succ_cnt = torch.sum(sanity_pred == 1)\n",
    "nz = sanity_pred.shape[0]\n",
    "accuracy = succ_cnt / nz\n",
    "print(\"accuracy\", accuracy)\n",
    "# breakpoint()\n",
    "############### sanity check part 1 end ################\n",
    "\n",
    "############# test on NTK Regression end #################\n",
    "\n",
    "\n",
    "\n",
    "# breakpoint()\n",
    "# print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy tensor(0.9800, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "############### sanity check part 1 start ################\n",
    "sanity_pred = process_query(cls1_test_ts, w_r, x_data, alpha)\n",
    "succ_cnt = torch.sum(sanity_pred == 1)\n",
    "nz = sanity_pred.shape[0]\n",
    "accuracy = succ_cnt / nz\n",
    "print(\"accuracy\", accuracy)\n",
    "# breakpoint()\n",
    "############### sanity check part 1 end ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "############### sanity check part 1 start ################\n",
    "sanity_pred = process_query(cls1_train_ts, w_r, x_data, alpha)\n",
    "succ_cnt = torch.sum(sanity_pred == 1)\n",
    "nz = sanity_pred.shape[0]\n",
    "accuracy = succ_cnt / nz\n",
    "print(\"accuracy\", accuracy)\n",
    "# breakpoint()\n",
    "############### sanity check part 1 end ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy tensor(0.9900, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "############### sanity check part 1 start ################\n",
    "sanity_pred = process_query(cls2_test_ts, w_r, x_data, alpha)\n",
    "succ_cnt = torch.sum(sanity_pred == -1)\n",
    "nz = sanity_pred.shape[0]\n",
    "accuracy = succ_cnt / nz\n",
    "print(\"accuracy\", accuracy)\n",
    "# breakpoint()\n",
    "############### sanity check part 1 end ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "############### sanity check part 1 start ################\n",
    "sanity_pred = process_query(cls2_train_ts, w_r, x_data, alpha)\n",
    "succ_cnt = torch.sum(sanity_pred == -1)\n",
    "nz = sanity_pred.shape[0]\n",
    "accuracy = succ_cnt / nz\n",
    "print(\"accuracy\", accuracy)\n",
    "# breakpoint()\n",
    "############### sanity check part 1 end ################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
